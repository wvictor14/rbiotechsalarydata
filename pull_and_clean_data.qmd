---
title: "Cleaning r/biotech Salary Data"
date: last-modified
date-modified: last-modified
params:
  outdir: ""
format:
  html:
    embed-resources: true
    toc: true
    toc-depth: 4
editor: visual
editor_options: 
  chunk_output_type: console
---

set out dir

```{r}
if (interactive()){
  outdir <- here::here()
} else {
  outdir <- here::here(params$outdir)
}
```

# libraries

```{r, message = FALSE, warning = FALSE}
library(readr)
library(here)
library(purrr)
library(glue)
library(lubridate)
library(forcats)
library(dplyr)
library(tidyr)
library(gt)
library(ggplot2)
library(skimr)
library(janitor)
library(stringr)
library(tictoc)
library(usethis)
library(reactable)
```

# preprocess excel data

[link to google sheets](https://docs.google.com/spreadsheets/d/1G0FmJhkOME_sv66hWmhnZS5qR2KMTY7nzkxksv46bfk/edit#gid=491268892)

I extract the sheets into separate csv files so that they can display on github and be more easily used.

```{r process-sheets, eval = TRUE}
# run this once, manually
library(googlesheets4)
gs4_deauth()
google_sheets_url <- 'https://docs.google.com/spreadsheets/d/1G0FmJhkOME_sv66hWmhnZS5qR2KMTY7nzkxksv46bfk/edit#gid=491268892'
sheet_names <- googlesheets4::sheet_names(google_sheets_url)
```

# yearly survey version differences

```{r}
sal <- sheet_names |>  
  # read it as character values to avoid list-column headaches
  map(
    \(x) read_sheet(google_sheets_url, sheet = x, col_types = 'c')
  ) 
sal <-  sal |> 
  set_names(sheet_names) |> 
  bind_rows(.id = 'sheet_name')
sal  |>  glimpse()
```

```{r}
sal |> count(sheet_name)
missing_variables_by_year <- sal |> 
  summarize(
    .by = sheet_name,
    across(everything(), ~sum(is.na(.)))
  ) |>  
  pivot_longer(
    cols = -c(sheet_name),
    names_to = 'variable',
    values_to = 'n_missing'
  ) |>  
  arrange(desc(sheet_name), desc(n_missing)) 
missing_variables_by_year |>   reactable(groupBy = 'sheet_name')
```

# Initial exploratory

## Completeness

Look at response rate per question (number of NAs):

```{r read_data}
# assess NAs
percent_na <- function(x, invert = FALSE) {
  p <- sum(is.na(x)) / length(x)
  if (invert) { p <- 1 - p}
  p
}

completeness <- sal |> 
  summarize(
    .by = sheet_name,
    across(everything(), ~percent_na(.x, invert = TRUE))
  )   |> 
  mutate(across(everything(), ~ifelse(. == 0, NA, .))) |> 
  pivot_longer(-sheet_name, names_to = 'variable', values_to = '% responded') |> 
  pivot_wider(names_from = sheet_name, values_from = '% responded')  

reactable_na <- function(df) {
  df |> 
    gt() |> 
    fmt_percent(columns = -variable, decimals = 0) |> 
    data_color(
      columns = -variable, 
      palette = c('white', 'blue'),
      na_color = 'white',
      domain = c(0, 1)) |> 
    sub_missing(missing_text = '0') |> 
    tab_options(table.width = px(500))
}
reactable_na(completeness) 
```


## Remove those with 0 answers:

```{r}
# remove variables that are all NA:
var_all_na <- sal |>  
  skim()  |>   
  filter(n_missing == nrow(sal)) |> 
  pull(skim_variable)

message('removing variables that are have all missing values')
sal_clean <- sal |> 
  select(-any_of(var_all_na))
message(glue(
  "{length(var_all_na)}/{ncol(sal)} columns removed that are all NA"
))
print(var_all_na)
```

## Rename column names

I rename column names to make them easier to call:

```{r}
# view changed colnames
tibble(original = colnames(sal)) |> 
  mutate(new = janitor::make_clean_names(original)) |> 
  gt() 
sal_clean <- janitor::clean_names(sal_clean)
```

Now I begin cleaning the variable values

# Column cleaning

It would be a massive effort to clean every column. Let's prioritize to most important ones:

-   Salary
-   base
-   target bonus (%)
-   equity
-   Title
-   Experience
-   years
-   degree
-   Location
-   country
-   city

If I have time, can look also at:

-   401k match

## salary

-   base
-   target bonus (%)
-   equity

There are a handful of responses with annual salary reportedly less than \$5000. There is one person that responded with "\$1" - we remove them. And then the remaining report a range from 105-210, which likely represent 105**k** - 210**k**, I multiple these ones by 1000.

### base

Which column corresponds to base salary?

```{r}
completeness |> filter(str_detect(tolower(variable), 'salary')) |>  reactable_na()
```

2025 we changed the question, added data validation so that it has to be digits

before 2025, it was a short-form text, so it needed a lot of data cleaning.


2025 looks like this

I rename to `compensation_annual_base_salary_pay_2025 ` first

```{r}
sal_clean <- sal_clean |> rename(
  compensation_annual_base_salary_pay_2025  = annual_base_salary_what_is_your_annual_base_salary_do_not_include_bonus_or_stocks_if_you_are_paid_hourly_multiply_by_2080_to_convert_to_yearly_assuming_you_work_40hr_week
) 
sal_clean <- sal_clean |> mutate(compensation_annual_base_salary_pay_2025 = as.numeric(compensation_annual_base_salary_pay_2025))

sal_clean |> 
  select(compensation_annual_base_salary_pay_2025 ) |> 
  ggplot(aes(x = compensation_annual_base_salary_pay_2025 )) + 
  geom_histogram() + 
  scale_x_continuous(labels = scales::dollar)
```

Since it looks good I will coaelesce 2025 with previous years:

```{r}
sal_clean <- sal_clean |> 
  mutate(compensation_annual_base_salary_pay = ifelse(
    is.na(compensation_annual_base_salary_pay), 
    compensation_annual_base_salary_pay_2025,
    compensation_annual_base_salary_pay
  )) |> 
  select(-compensation_annual_base_salary_pay_2025)
```

Now what follows is cleaning the data:
- remove too low salaries (<5k)

```{r}
# make numeric
sal_clean <- sal_clean |>  
  mutate(
    across(
      c(compensation_annual_base_salary_pay, 
        compensation_annual_target_bonus), ~as.numeric(.x))
  )

sal_clean |>  
  ggplot(aes(x = compensation_annual_base_salary_pay)) + 
  geom_histogram() +
  scale_x_continuous(labels = scales::number)

# a bunch of salary entries that are <1000:
sal_clean |> 
  filter(compensation_annual_base_salary_pay < 5000) |> 
  count(compensation_annual_base_salary_pay)

# remove guy with "1" in base
sal_clean_filt <- sal_clean |> 
  filter(compensation_annual_base_salary_pay > 1)
n_removed <- nrow(sal_clean) - nrow(sal_clean_filt)

# 1 guy added extra 0
sal_clean_filt <- sal_clean_filt |> 
  mutate(compensation_annual_base_salary_pay = ifelse(
    compensation_annual_base_salary_pay == 1350000 &
      sheet_name == '2023', 
    1350000/10, 
    compensation_annual_base_salary_pay
  ))

# for the remainder of individuals with salary < 5000 (all in hundreds), 
# multiply by 1000
sal_clean_filt <- sal_clean_filt |>  
  mutate(
    salary_base = ifelse(
      compensation_annual_base_salary_pay < 1000,
      compensation_annual_base_salary_pay*1000, 
      compensation_annual_base_salary_pay     
    ))

n_changed <- sal_clean_filt |> 
  filter(salary_base != compensation_annual_base_salary_pay) |>
  nrow() 
```

We removed `r n_removed` data point, and changed / cleaned `r n_changed`

```{r}
sal_clean_filt |> 
  filter(salary_base != compensation_annual_base_salary_pay) |>
  select(compensation_annual_base_salary_pay, salary_base) |> 
  gt()
```

### target bonus

Which column corresponds to bonus?

```{r}
completeness |> filter(str_detect(tolower(variable), 'bonus')) |>  reactable_na()
```

```{r}
sal_clean_filt |>  colnames() |>  str_subset('bonus')
```

2025: `annual_target_bonus_in_percentage_percent_this_should_be_stipulated_prior_to_your_employment_do_not_include_one_time_bonuses_spot_bonuses_signing_bonuses_referral_bonuses`  
2024: `compensation_annual_target_bonus`

```{r}
sal_clean_filt  |> 
  count(annual_target_bonus_in_percentage_percent_this_should_be_stipulated_prior_to_your_employment_do_not_include_one_time_bonuses_spot_bonuses_signing_bonuses_referral_bonuses)  |> 
  set_names(nm = c('bonus', 'n')) |>  
  gt()
```

2025 looks good, combine it 

leave it in the data, but rename to shorter: `bonus_pct_2025`

```{r}
sal_clean_filt <- sal_clean_filt |> 
  rename(bonus_pct_2025 = annual_target_bonus_in_percentage_percent_this_should_be_stipulated_prior_to_your_employment_do_not_include_one_time_bonuses_spot_bonuses_signing_bonuses_referral_bonuses) |> 
  
  mutate(compensation_annual_target_bonus = case_when(
    !is.na(bonus_pct_2025) ~ as.numeric(bonus_pct_2025),
    TRUE ~ compensation_annual_target_bonus
  )) 
```

Look at the completeness of bonus now:

```{r}
sal_clean_filt |> 
  count(.by = sheet_name, missing_bonus = is.na(compensation_annual_target_bonus)) |>   
  mutate(.by = .by, p = n / sum(n)) |> 
  pivot_wider(
    names_from = .by, values_from = c(n, p), names_vary = 'slowest'
  ) |> 
  gt() |> 
  fmt_percent(contains('p_')) |>
  data_color(
    columns = contains('p_'), 
    palette = c('grey', 'forestgreen'),
    na_color = 'white',
    domain = c(0, 1)) |> 
  tab_spanner_delim(columns = -missing_bonus, delim = '_', reverse = TRUE)
```

**Before 2025:**

is a mix of % and \$ amount

I combine this with annual base to create two new variables: bonus_pct, bonus (raw)

My strategy:

1.  Remove special characters, except periods which represent decimals
2.  convert to numeric, which has two impacts:

-   "Not Applicable/None" entries will be converted to NAs
-   percentages will be converted from those values that are less than "50"
-   raw currency values will be simply those that are above 1000

3.  If there is a range of values, then I keep the higher value, since bonus is typically interpreted as the maximum bonus amount, depending on company and individual performance

```{r}
sal_clean_filt |> 
  select(compensation_annual_base_salary_pay, 
         compensation_annual_target_bonus) |>  
  head(n = 20) |> gt() 

sal_clean_filt <- sal_clean_filt |> 
  mutate(
    bonus_cleaned = compensation_annual_target_bonus |> 
      
      # remove special characters
      str_remove_all('[\\$,\\%]') |>
      
      # remove any non-digits at beginning or end of string
      str_remove('^[^\\d]+') |> 
      str_remove('[^\\d]+$') |> 
      
      # if there is text between numbers, 
      # split it as likely this represents a range
      str_split('[^\\d\\.]+') |> 
      
      # convert to numeric
      # if it is a range, keep the highest value
      map_dbl(\(x) x |> as.numeric() |> max()) 
  ) |> 
  
  mutate(bonus_pct = case_when(
    bonus_cleaned < 50 ~ bonus_cleaned/100,
    bonus_cleaned > 1000 ~ bonus_cleaned / salary_base,
    TRUE ~ 0
  ),
  bonus = case_when(
    bonus_cleaned < 50 ~ bonus_pct * salary_base,
    bonus_cleaned > 1000 ~ bonus_cleaned,
    TRUE ~ 0
  ))
```

Let's look at the cleaned bonus data vs the original:

```{r}
sal_clean_filt |> 
  
  # take 12 rows, 6 that are different, and then 6 not
  mutate(different = compensation_annual_target_bonus != bonus_cleaned) |> 
  slice_sample(n = 6, by = different) |>  
  
  count(salary_base, compensation_annual_target_bonus, 
        bonus_cleaned, bonus_pct, bonus)  |> 
  arrange(salary_base) |> 
  gt() |> 
  fmt_percent(bonus_pct) |> 
  fmt_currency(c(salary_base, bonus)) |> 
  sub_missing()


n_changed_bonus <- sal_clean_filt |> 
  filter(salary_base != compensation_annual_base_salary_pay) |>
  nrow() 
```

I converted bonus into % and raw \$. This involved modifying `r n_changed_bonus` bonus data points.

#### filter

These are the responses that put a bonus amount that is nonsensical (> 100%)

I remove these responses completely

```{r}
# bonus > 100% of base
sal_clean_filt |> 
  filter(bonus_pct >= 1)  |> 
  select(bonus_pct, bonus_pct_2025, bonus_cleaned, compensation_annual_base_salary_pay)

sal_clean_filt <- sal_clean_filt |> 
  filter(bonus_pct < 1) 
```

### total comp

```{r}
sal_clean_filt <- sal_clean_filt |> 
  mutate(salary_total = salary_base + bonus)

sal_clean_filt |>  count(is.na(salary_total))
sal_clean_filt |>  count(is.na(salary_base))
sal_clean_filt |>  count(is.na(bonus))
```

### equity

NOT CURRENTLY ATTEMPTED. Prioritize other data first.

Equity is a little bit complicated:

Some are reported as options, some are reported in 1000s e.g. "15k" vs "15000" Some are reported in \$ amount Some say "it varies per year" There are a few that report %, is that amount percentage from base in \$ or in options??

1.  We set "Not Applicable/None" to 0
2.  Set responses that report %, to NA (I don't want to deal with this and it is a small number of responses)
3.  We then create two variables, equity_options, equity_currency_value

-   `equity_currency_value` takes those data points that start with a dollar sign \$
-   `equity_options` is everything else
-   treat this the same as base salary:
-   clean and then:
-   where if it is less than 1000, multiple by 1000

3.  Convert everything to numeric

```{r}
sal_clean_filt |> 
  pull(compensation_annual_equity_stock_option) |>  
  unique() |> 
  head(n = 20) 
```

## Title

What variables correspond to job title?

```{r}
completeness |> filter(str_detect(tolower(variable), 'title')) |>  reactable_na()
```

2025: `What is your official job title? This should match the title that was present on your offer letter. Some examples: Research Associate, Scientist, Scientist I/II/III, Senior Scientist, Principal Scientist, Manager, Lab Technician, VP, Director etc. If your job title includes additional detail, please include e.g. Director of Bioinformatics`

2024: `Role / Title of current position`

rename 2025 variable to `title_2025`

And then merge with 2024 to: `role_title_of_current_position`

```{r}
sal_clean_filt <- sal_clean_filt |> 
  rename(title_2025 = what_is_your_official_job_title_this_should_match_the_title_that_was_present_on_your_offer_letter_some_examples_research_associate_scientist_scientist_i_ii_iii_senior_scientist_principal_scientist_manager_lab_technician_vp_director_etc_if_your_job_title_includes_additional_detail_please_include_e_g_director_of_bioinformatics) |> 
  mutate(role_title_of_current_position = case_when(
    is.na(role_title_of_current_position) ~ title_2025,
    TRUE ~ role_title_of_current_position
  ))
```

pre-2025 cleaning: 

Title is very important, but also very messy. Titles can have different meanings (compensation, experience, responsibilities) between companies, and location.

```{r}
sal_clean_filt |> 
  count(role_title_of_current_position) |>
  slice_sample(n=10) |> 
  gt() 
```

### filtering

Remove some obvious rows

```{r}
sal_clean_filt <- sal_clean_filt |> 
  filter(role_title_of_current_position != 'pimp')
```

### Standardize titles

It's a lot of work to standardize titles, so I focus on what I know best, scientist-relaeta Let me intialize some empty columns

```{r}
sal_clean_filt <- sal_clean_filt |> 
  mutate(
    title_category = NA_character_, 
    title_general = NA_character_, 
    title_detail = NA_character_
  )
```

#### Scientist

It's a lot of work to standardize titles, so I focus on what I know best, scientist

Scientist:

-   Research Associate
-   Associate Scientist
-   Scientist
-   Senior Scientist
-   Staff Scientist
-   Principal Scientist

I'm going to create two new variables

-   `title_category` - Set this to `Scientist`
-   `title_general` - A variable that includes general scientist + levels, e.g. Sci **III**, and **Associate** Sci
-   `title_detail` - Contains the other detail of job title, e.g. **Research**, **Clinical**

```{r}
# all roles matching "Scientist"
sal_clean_filt |> 
  filter(str_detect(
    role_title_of_current_position, regex('Scientist', ignore_case = FALSE))) |> 
  count(role_title_of_current_position) |> head(25) |> gt()
```

Try a different approach:

Hierarchical, see case_when

The order of the statements are impactful e.g.

-   If they have associate, they will associate scientists
-   If they have associate and "principal" they will be principal scientist

```{r}
sal_clean_filt <- sal_clean_filt |>
  mutate(
    # title_category
    title_category =  
      ifelse(
        str_detect(
          role_title_of_current_position, regex('Scientist', ignore_case = TRUE)),
        'Scientist',
        title_category
      ),
    
    # scratch
    a = title_category == 'Scientist',
    b = role_title_of_current_position |> 
      str_replace_all('sr\\.?', 'Senior'),
    
    # title detail
    title_detail = ifelse(
      a,
      role_title_of_current_position |> 
        str_remove_all(
          regex('(Associate|Scientist|Principal|Senior)*', ignore_case = TRUE)) |> 
        str_replace_all('[:punct:]+', ' ') # |> 
      # str_replace_all('\\s{2,}', ' ')
      ,
      NA
    )
  ) |> 
  
  # title_gen most specific to most general
  mutate(title_general = case_when(
    
    a & str_detect(
      b, regex('Principal', ignore_case = TRUE)) ~ 'Principal Scientist',
    a & str_detect(
      b, regex('Senior', ignore_case = TRUE)) ~ 'Senior Scientist',
    a & str_detect(
      b, regex('Associate', ignore_case = TRUE)) ~ 'Associate Scientist',
    a ~ 'Scientist',
  )) |> 
  
  # clean
  select(-a, -b)

sal_clean_filt |>  
  count(role_title_of_current_position, title_general, title_detail) |>
  slice_sample(n = 20) |>  gt()

sal_clean_filt |>  count(title_general) |> gt()
```

##### filter

remove some outliers upon inspection post deployment

```{r}
# salary > 800k as scientist
remove <- sal_clean_filt |> 
  filter(
    year(mdy_hms(timestamp)) == 2024,
    month(mdy_hms(timestamp)) == 5,
    day(mdy_hms(timestamp)) == 22,
    role_title_of_current_position == 'Scientist'
  ) |> 
  pull(timestamp)

# removed
sal_clean_filt |>  filter(timestamp == remove)
sal_clean_filt <- sal_clean_filt |>  filter(timestamp != remove)
```

#### Directors and VP

Same approach as for Scientist, but these are the levels:

```{r}
sal_clean_filt |> 
  filter(str_detect(
    role_title_of_current_position, regex('(Dir(ector)*)|(AD)', ignore_case = TRUE))) |> 
  count(role_title_of_current_position) |>  slice_sample(n = 25) |> gt()
```

```{r}
sal_clean_filt <- sal_clean_filt |>
  mutate(
    
    # title category
    title_category =  
      ifelse(
        str_detect(
          role_title_of_current_position, regex('(Director|\\bAD\\b|\\bDir\\b)', ignore_case = TRUE)),
        'Director',
        title_category
      ),
    
    # scratch for concise coding
    a = title_category == 'Director',
    
    # preprocessed 
    b = role_title_of_current_position |> 
      str_replace_all('sr\\.?', 'Senior') |> 
      str_replace_all('\\bAD\\b', 'Associate Director') |> 
      str_replace_all('\\bAssoc\\.?\\b', 'Associate') |> 
      str_replace_all('\\bDir\\.?\\b', 'Director') 
    ,
    
    # title detail
    title_detail = ifelse(
      a,
      b |> 
        
        # remove the level part + director
        str_remove_all(
          regex('(Associate|Director|Senior|Executive)*', ignore_case = TRUE)) |> 
        str_replace_all('[:punct:]+', ' ') # |> 
      # str_replace_all('\\s{2,}', ' ')
      ,
      title_detail
    )) |> 
  
  # title_gen most specific to most general
  mutate(title_general = case_when(
    
    a & str_detect(
      b, regex('Executive', ignore_case = TRUE)) ~ 'Executive Director',
    a & str_detect(
      b, regex('Senior', ignore_case = TRUE)) ~ 'Senior Director',
    a & str_detect(
      b, regex('Associate', ignore_case = TRUE)) ~ 'Associate Director',
    a ~ 'Director',
    .default = title_general
  )) |> 
  
  # clean
  select(-a, -b) 
sal_clean_filt |> 
  count(
    role_title_of_current_position, title_category, 
    title_general, title_detail) |>
  slice_sample(n = 20) |>  
  gt()

sal_clean_filt |>  
  filter(title_category == 'Director') |>  count(title_general) |> gt()
```

-   Associate Director
-   Director
-   Senior Director
-   Executive Director

#### VP

There's not many VPs

```{r}
sal_clean_filt |> 
  filter(str_detect(
    role_title_of_current_position, regex('(VP|Vice Principal)', ignore_case = TRUE))) |> 
  count(role_title_of_current_position) |> gt()
```

```{r}
sal_clean_filt <- sal_clean_filt |>
  mutate(
    title_category =  
      ifelse(
        str_detect(
          role_title_of_current_position, 
          regex('(VP|Vice Principal)', ignore_case = TRUE)),
        'VP',
        title_category
      ),
    
    # scratch for concise coding
    a = title_category == 'VP',
    
    # preprocessed 
    b = role_title_of_current_position |> 
      str_replace_all(regex('vp', ignore_case = TRUE), 'VP')
    ,
    
    # title detail
    title_detail = ifelse(
      a,
      b |> 
        
        # remove the level part + title_category
        str_remove_all(
          regex('S?VP', ignore_case = TRUE)) |> 
        str_replace_all('[:punct:]+', ' ') |> 
        str_replace_all('\\s{2,}', ' ') |> 
        str_trim()
      ,
      title_detail
    )) |> 
  
  # title_gen most specific to most general
  mutate(title_general = case_when(
    
    a & str_detect(
      b, regex('SVP', ignore_case = TRUE)) ~ 'SVP',
    a ~ 'VP',
    .default = title_general
  )) |> 
  
  # clean
  select(-a, -b)  

sal_clean_filt |> 
  filter(str_detect(
    role_title_of_current_position, regex('vp', ignore_case = TRUE))) |> 
  count(
    role_title_of_current_position, title_category, 
    title_general, title_detail) |>  
  gt()

sal_clean_filt |>  
  filter(title_category == 'VP') |>  count(title_general) |> gt()
```

#### Research Associate

```{r}
sal_clean_filt |> 
  filter(str_detect(
    role_title_of_current_position, 
    regex('(Research Associate|\\bRA\\b)', ignore_case = TRUE)
  )) |> 
  count(role_title_of_current_position) |> gt()
```

```{r}
sal_clean_filt <- sal_clean_filt |>
  mutate(
    # title_category
    title_category =  
      ifelse(
        str_detect(
          role_title_of_current_position, 
          regex('(Research Associate|\\bRA\\b)', ignore_case = TRUE)),
        'Research Associate',
        title_category
      ),
    
    # scratch
    a = title_category == 'Research Associate',
    b = role_title_of_current_position |> 
      str_replace_all('[Ss]r\\.?', 'Senior'),
    
    # title detail
    title_detail = ifelse(
      a,
      role_title_of_current_position |>
        str_remove_all(
          regex('(Research|Associate|Scientist|Senior|\\bRA\\b)*', 
                ignore_case = TRUE)) |> 
        str_replace_all('[:punct:]+', ' ')  |> 
        str_replace_all('\\s{2,}', ' ')
      ,
      title_detail
    )
  ) |> 
  
  # title_gen most specific to most general
  mutate(title_general = case_when(
    a & str_detect(
      b, regex('Senior', ignore_case = TRUE)) ~ 'Senior Research Associate',
    a ~ 'Research Associate',
    .default = title_general
  )) |> 
  
  # clean
  select(-a, -b)

sal_clean_filt |> 
  filter(str_detect(
    role_title_of_current_position, regex('(Research Associate|\\bRA\\b)', ignore_case = TRUE))) |> 
  count(
    role_title_of_current_position, title_category, 
    title_general, title_detail) |>  
  gt()

sal_clean_filt |>  
  filter(title_category == 'Research Associate') |>  count(title_general) |> gt()
```

##### filter

I filter out an outlier sample, looks like they incorrectly inputted bonus:

```{r, eval = FALSE}
n_1 <- nrow(sal_clean_filt)
sal_clean_filt |> 
  dplyr::filter((
    str_detect(timestamp, '10/31/2023') & 
      role_title_of_current_position == 'Sr Clinical Research Associate')
  ) |> 
  gt::gt()
sal_clean_filt <- sal_clean_filt |> 
  dplyr::filter(!(
    str_detect(timestamp, '10/31/2023') & 
      role_title_of_current_position == 'Sr Clinical Research Associate')
  )
.diff <- nrow(sal_clean_filt) - n_1
stopifnot(.diff == -1)
```

### Roles that have not been processed

Look at the remaining roles that I have not tried to process.

```{r}
sal_clean_filt |>  
  filter(is.na(title_category)) |> 
  distinct(role_title_of_current_position) |>  
  reactable()
```

## Experience

What variables correspond to years of experience?

```{r}
completeness |> filter(str_detect(tolower(variable), 'experience')) |>  reactable_na()
```

2025: `Please enter your total years of experience in the field DO NOT INCLUDE years in BSc, Masters, PhD, or post-bacc/post-doc`

2024: `Years of Experience`

rename 2025 variable to `yoe_2025`

And then merge with 2024 to: `years_of_experience`

```{r}
sal_clean_filt <- sal_clean_filt |> 
  rename(yoe_2025 = please_enter_your_total_years_of_experience_in_the_field_do_not_include_years_in_b_sc_masters_ph_d_or_post_bacc_post_doc) |> 
  mutate(years_of_experience = case_when(
    is.na(years_of_experience) ~ yoe_2025,
    TRUE ~ years_of_experience
  ))
```

**pre-2025 cleaning:**

```{r}
sal_clean_filt |> 
  count(years_of_experience) |> gt()
```

only 1 will be converted to NA

```{r}
n_before <- sum(is.na(sal_clean_filt$years_of_experience)) 
sal_clean_filt <- sal_clean_filt |> 
  mutate(years_of_experience = as.numeric(years_of_experience)) 
n_after <- sum(is.na(sal_clean_filt$years_of_experience))
message(glue('# NAs\nbefore: {n_before}\nafter: {n_after}'))
```

#### degree

What variables correspond to education?

```{r}
completeness |> filter(str_detect(tolower(variable), '(degree|edu)')) |>  reactable_na()
```

2025: `Select the highest level of education that you have that's relevant to your occupation. If you have multiple (e.g. PhD + MD) please select "Other" and describe`

2024: `Select the highest level of education that you have that's relevant to your occupation. If you have multiple (e.g. PhD + MD) please select "Other" and describe`

2023: `Highest achieved Formal Education`

rename 2025 variable to `highest_degree_2025`

And then merge with 2024 to: `what_degrees_do_you_have`

```{r}
sal_clean_filt |>  colnames() |>  str_subset('education')
sal_clean_filt <- sal_clean_filt |> 
  rename(highest_degree_2025 = select_the_highest_level_of_education_that_you_have_thats_relevant_to_your_occupation_if_you_have_multiple_e_g_ph_d_md_please_select_other_and_describe) |> 
  mutate(what_degrees_do_you_have = case_when(
    #2025
    is.na(what_degrees_do_you_have) &
      is.na(highest_achieved_formal_education) ~ highest_degree_2025,
    
    # 2023 2022
    is.na(what_degrees_do_you_have) & 
      is.na(highest_degree_2025) ~ highest_achieved_formal_education,
    
    #2024
    TRUE ~ what_degrees_do_you_have
  ))
```

**pre-2025 cleaning:**

```{r}
sal_clean_filt |> 
  count(what_degrees_do_you_have) |>  gt()
```

contains all degrees, but let's simplify to the highest degree:

e.g.

-   "High School or Equivalent, Bachelors or Equivalent, Masters or Equivalent, PhD or Equivalent"
-   "Bachelors or Equivalent, Masters or Equivalent, PhD or Equivalent"
-   "Bachelors or Equivalent, PhD or Equivalent"
-   "PhD or Equivalent"

should all just be "PhD"

Below code assumes highest degree is the last listed degree

```{r}
sal_clean_filt <- sal_clean_filt |> 
  mutate(experience_highest_degree =  str_extract(
    what_degrees_do_you_have,
    '(?<=,|^)[^,]+$'
  ) |> 
    str_replace('M\\.D\\.', 'MD') |> 
    str_remove('or Equivalent') |> 
    str_replace('MD/Pharm.*', 'MD')
  ) 

# View Changes
sal_clean_filt |>  
  count(is.na(experience_highest_degree), is.na(what_degrees_do_you_have))

sal_clean_filt |>
  count(experience_highest_degree, what_degrees_do_you_have) |>  
  gt()
```

## Location

What variables correspond to location?

```{r}
completeness |> filter(str_detect(tolower(variable), '(located|city|country|state|province)')) |>  reactable_na()
sal_clean_filt |>  colnames() |>  str_subset('(country|city|state|provin)')
```

2025: `Which country do you work in?`, `What City do you work in?`, `Which US state do you work in?`, `Which Canadian Province do you work in?`

2024: `Where are you located?`

<2023: `What country do you work in?`, `Where is the closest major city or hub?`


**pre-2025 cleaning:**

```{r}
sal_clean_filt |> 
  count(where_is_the_closest_major_city_or_hub, where_are_you_located) |> 
  gt()

sal_clean_filt |> 
  count(
    where_are_you_located, what_country_do_you_work_in,
    where_is_the_closest_major_city_or_hub) |>  
  gt()
```

Location is quite messy data consisting of free-form responses spread between 3 variables:

-   `where_are_you_located` contains Countries (USA, Canada, etc.), states (CO, Carolinas, etc.)

This is not a required question so there are 174 responses that did not respond, and this also included an "other" freeform option.

-   Pharma Central (NY, NJ, PA)
-   New England (MA, CT, RI, NH, VT, ME)
-   DC Metro Area (DC, VA, MD, DE)
-   Carolinas & Southeast (From NC to AR, South FL and LA)
-   Midwest (From OH to KS, North to ND)
-   South & Mountain West (TX to AZ, North to MT)
-   West Coast (California & Pacific Northwest)
-   Other US Location (HI, AK, PR, etc.)
-   Canada
-   United Kingdom and Ireland
-   Germany
-   Other:

The 174 missing responses have values for these other two variables. I think this is due to the survey changing the question at some point, probably due to feedback.

-   `what_country_do_you_work_in` seems to all be countries, but not harmonized e.g.: Usa, usa, United States
-   `where_is_the_closest_major_city_or_hub` mixed bag: Bay area, Boston, san diego, Research Triangle,

Here I create one new location variable `location_country`, that, unlike the other variables, cover \>90% of the data

```{r}
USA <- c(
  "Pharma Central (NY, NJ, PA)",
  "New England (MA, CT, RI, NH, VT, ME)",
  "DC Metro Area (DC, VA, MD, DE)",
  "Carolinas & Southeast (From NC to AR, South FL and LA)",
  "Midwest (From OH to KS, North to ND)",
  "South & Mountain West (TX to AZ, North to MT)",
  "West Coast (California & Pacific Northwest)",
  "Other US Location (HI, AK, PR, etc.)"
)

usa_locations <- c(
  'baltimore',
  'boston',
  'bay area', 
  'baltimore',
  'boulder',
  'california',
  'cambridge',
  'carlsbad',
  'jersey', 'maine',
  'chicago',
  '\\bdc\\b',
  'denver',
  'durham',
  'hayward',
  'hungary',
  'indianapolis',
  'kansas',
  '\\bla\\b',
  'los angeles',
  'maryland',
  'midwest',
  'new york',
  '\\bnj\\b',
  '\\bny[c]?\\b',
  'ohio',
  'philadelphia',
  'phoenix',
  'pittsburgh',
  'raleigh',
  'san diego',
  'ridgefield',
  'rockville',
  'rtp\\b',
  'sacramento',
  'salt lake',
  'seattle',
  'san francisco',
  'socal',
  'united states',
  'u\\.s\\.a',
  'washington'
) 

usa_locations <- str_c('(', str_c(usa_locations, collapse = '|'), ')')

sal_clean_filt <- sal_clean_filt |> 
  mutate(
    
    # prep raw location data
    location_raw_data = case_when(
      !is.na(what_country_do_you_work_in) ~ what_country_do_you_work_in,
      !is.na(where_are_you_located) ~ where_are_you_located, 
      !is.na(where_is_the_closest_major_city_or_hub) ~ where_is_the_closest_major_city_or_hub,
      .default = where_is_the_closest_major_city_or_hub
    ) |> 
      tolower(),
    
    # matching
    location_country = case_when(
      
      ### 2025 data
      !is.na(which_country_do_you_work_in) ~ which_country_do_you_work_in,
      
      ### usa 
      location_raw_data %in% c(
        tolower(USA), 
        'co', 
        'san diego, ca', 
        'united states'
      ) ~ 'United States of America',
      
      location_raw_data |> 
        str_detect(regex('usa?', ignore_case = TRUE)) ~ 
        'United States of America', 
      
      location_raw_data |>
        str_detect(regex(usa_locations, ignore_case = TRUE), ) ~ 
        'United States of America',
      ### UK
      location_raw_data |> 
        str_detect('(u\\.k|dundee|ireland)') ~ 'United Kingdom',
      location_raw_data %in% c(
        'united kingdom and ireland', 'uk') ~ 'United Kingdom',
      
      ### other
      location_raw_data %in% 
        c('canada', 'united states of america',
          'belgium', 'france', 'spain', 'united kingdom', 'benelux', 'germany',
          'sweden', 'switzerland', 'denmark',
          'singapore', 'india', 'australia') ~ location_raw_data,
      
      location_raw_data |>  str_detect('toronto') ~ 'Canada',
      TRUE ~ NA
      
    ),
    location_country = str_to_title(location_country)
  )

sal_clean_filt |> 
  count(location_country, location_raw_data,
        where_are_you_located, what_country_do_you_work_in, 
        where_is_the_closest_major_city_or_hub) |> 
  arrange(location_country) |>  gt()
```

### location granular

for selecting within country:

```{r}
sal_clean_filt <- sal_clean_filt |> 
  mutate(
    location_granular = 
      coalesce(
        which_us_state_do_you_work_in,
        which_canadian_province_do_you_work_in,
        where_is_the_closest_major_city_or_hub, where_are_you_located)
  )  
sal_clean_filt |> 
  count(
    location_granular, 
    
        which_us_state_do_you_work_in,
        which_canadian_province_do_you_work_in,
    where_is_the_closest_major_city_or_hub, 
    where_are_you_located) |>  gt() 
```

# Completeness

Compare the missingness of original location variables vs the cleaned `location_country` variable:

```{r}
sal_clean_filt |> 
  summarize(
    across(c(
      location_country,
      location_granular,
      where_are_you_located, 
      what_country_do_you_work_in, 
      where_is_the_closest_major_city_or_hub), 
      ~ percent_na(.x))
  ) |> 
  pivot_longer(everything(), names_to = 'column', values_to = '% missing')
```

# time

```{r}
sal_clean_filt <- sal_clean_filt |> 
  mutate(timestamp = mdy_hms(timestamp),
         year = year(timestamp),
         month = month(timestamp),
         day = day(timestamp)) |> 
  select(timestamp, year:day, everything())
```

# write out the data

```{r}
sal_clean_filt |>
  mutate(date = str_extract(as.character(timestamp), "^[-\\w]+")) |> 
  select(
    date, 
    location_country, 
    title_category, title_general, title_detail,
    salary_base, bonus_pct, bonus,
    
    # need to fix these
    years_of_experience, what_degrees_do_you_have,
    
    # the original data
    where_are_you_located, what_country_do_you_work_in,
    role_title_of_current_position,
    everything(),
    -timestamp, -bonus_cleaned, -year, -month, -day
  ) |> 
  write_csv(here::here(outdir , 'salary_results_cleaned.csv'))
```
